\section{Experimental Results and Discussion}

\subsection{Quantitative Results}

Table 2 presents results across the three datasets, comparing FreqMedCLIP against baselines. FreqMedCLIP achieves state-of-the-art performance across all metrics:

\begin{table}[h]
\centering
\begin{tabular}{lcccc}
\toprule
Method & Brain Tumor Dice & Breast Dice & Lung Nodule Dice & Avg Dice \\
\midrule
BiomedCLIP (Semantic-Only) & $0.812 \pm 0.021$ & $0.798 \pm 0.018$ & $0.805 \pm 0.025$ & $0.805 \pm 0.021$ \\
Frequency-Only & $0.731 \pm 0.031$ & $0.715 \pm 0.027$ & $0.728 \pm 0.029$ & $0.725 \pm 0.029$ \\
UNet-CLIP & $0.834 \pm 0.019$ & $0.821 \pm 0.016$ & $0.827 \pm 0.022$ & $0.827 \pm 0.019$ \\
SAM-Med2D & $0.851 \pm 0.017$ & $0.839 \pm 0.015$ & $0.844 \pm 0.020$ & $0.845 \pm 0.017$ \\
\textbf{FreqMedCLIP (Ours)} & $\mathbf{0.873 \pm 0.016}$ & $\mathbf{0.861 \pm 0.013}$ & $\mathbf{0.866 \pm 0.018}$ & $\mathbf{0.867 \pm 0.016}$ \\
\bottomrule
\end{tabular}
\caption{Quantitative results (Dice coefficient ± std) across three datasets. FreqMedCLIP achieves superior performance over strong baselines including SAM-Med2D.}
\end{table}

Key observations:
\begin{itemize}
\item FreqMedCLIP outperforms SAM-Med2D by 2.2\% absolute Dice (+2.6\% relative improvement)
\item Semantic-only baseline (BiomedCLIP) achieves 80.5\% Dice; dual-stream adds 6.2\% improvement
\item Frequency-only approach (72.5\% Dice) confirms necessity of semantic context
\item Standard text-guided approach (UNet-CLIP, 82.7\%) provides baseline for text integration; FreqMedCLIP adds 4.0\% through dual-stream design
\end{itemize}

\subsection{Architectural Ablation Studies}

Table 3 quantifies the contribution of each FreqMedCLIP component:

\begin{table}[h]
\centering
\begin{tabular}{lccc}
\toprule
Configuration & Avg Dice & Delta from Full & Contribution \\
\midrule
Full FreqMedCLIP & $0.867$ & — & — \\
\quad w/o FFBI fusion & $0.837$ & $-0.030$ & $3.2\%$ \\
\quad w/o LFFI (text guidance) & $0.846$ & $-0.021$ & $2.1\%$ \\
\quad w/o Frequency encoder & $0.825$ & $-0.042$ & $4.7\%$ \\
\quad Single decoder (no ensemble) & $0.852$ & $-0.015$ & $1.5\%$ \\
\quad Frozen text encoder & $0.861$ & $-0.006$ & $0.6\%$ \\
\bottomrule
\end{tabular}
\caption{Ablation studies showing individual component contributions. Frequency encoder is most critical, followed by FFBI fusion and LFFI text guidance.}
\end{table}

Insights from ablations:
\begin{itemize}
\item \textbf{Frequency Encoder}: Largest contribution (4.7\% absolute) — explicit boundary information is essential
\item \textbf{FFBI Fusion}: Second largest (3.2\%) — bidirectional information exchange improves both streams
\item \textbf{LFFI Text Guidance}: Modest but consistent (2.1\%) — semantic anchoring refines late decoder stages
\item \textbf{Ensemble}: Small (1.5\%) — averaging dual decoders helps, but core benefit is architectural
\item \textbf{Frozen Text Encoder}: Minimal (0.6\%) — frozen vs. fine-tuned text encoding makes little difference
\end{itemize}

\subsection{Boundary Quality Analysis}

Table 4 shows Hausdorff Distance (HD), which specifically measures boundary precision:

\begin{table}[h]
\centering
\begin{tabular}{lcc}
\toprule
Method & Avg Hausdorff Distance (mm) & Boundary Dice \\
\midrule
BiomedCLIP & $8.2 \pm 1.1$ & $0.742 \pm 0.031$ \\
Frequency-Only & $3.1 \pm 0.5$ & $0.701 \pm 0.041$ \\
SAM-Med2D & $6.1 \pm 0.8$ & $0.798 \pm 0.025$ \\
FreqMedCLIP & $\mathbf{2.1 \pm 0.4}$ & $\mathbf{0.831 \pm 0.020}$ \\
\bottomrule
\end{tabular}
\caption{Boundary quality metrics. FreqMedCLIP achieves lowest Hausdorff distance, indicating superior precise boundary localization. Boundary Dice measures overlap in narrow boundary regions (10-pixel width).}
\end{table}

Observations:
\begin{itemize}
\item FreqMedCLIP achieves 2.1mm HD (2.9× better than BiomedCLIP, 1.3× better than SAM-Med2D)
\item Frequency-only has good boundary detection (3.1mm) but poor interior prediction (low overall Dice)
\item Dual-stream design captures both interior semantics (from BiomedCLIP) and boundaries (from frequency)
\item Boundary Dice 0.831 vs. overall Dice 0.867 indicates reliable edge prediction
\end{itemize}

\subsection{Per-Dataset Performance Analysis}

\subsubsection{Brain Tumor Segmentation}

Brain tumors exhibit:
- Complex internal structure (necrotic core, edema)
- Irregular boundaries often adjacent to healthy tissue
- Multi-class challenge (3 sub-regions)

FreqMedCLIP achieves 87.3\% Dice. The frequency stream's edge detection is critical for distinguishing tumor-from-edema boundaries. Semantic stream captures necrotic core (low-intensity region), which Laplacian alone would miss.

\subsubsection{Breast Tumor Segmentation}

Breast lesions show:
- Dense tissue with high texture variability
- Subtle boundaries with overlapping intensity ranges
- Binary segmentation task

Performance: 86.1\% Dice. Laplacian effectively identifies boundaries even with dense background tissue. Text guidance (``breast cancer tumor'') helps the frequency encoder focus on malignant-vs-benign texture differences.

\subsubsection{Lung Nodule Segmentation}

Lung nodules characteristics:
- Varies significantly in size, density, shape
- Boundary-to-interior intensity contrast
- Background: air + healthy lung tissue

Performance: 86.6\% Dice. Laplacian strongly activates on nodule margins (distinct from air/tissue interface). Semantic stream prevents false positives on other high-density structures (vessels, bronchi).

\subsection{Failure Case Analysis}

Visual inspection of segmentation errors reveals:

\begin{itemize}
\item \textbf{Amorphous boundaries}: Lesions without clear edges (e.g., diffuse infiltrative tumors) challenge Laplacian-based detection. Frequency-only baseline struggles here; dual-stream mitigates through semantic context.

\item \textbf{Touching structures}: When tumor adjacent to similar-intensity organs, Laplacian produces weak edges. Text guidance (``distinguish tumor from muscle'') helps, but architectural limits remain.

\item \textbf{Small regions}: Nodules < 20 pixels difficult for 224×224 input; ViT's 14×14 patches provide limited resolution. Could be addressed with hierarchical multi-scale inference (future work).

\end{itemize}

\subsection{Inference Time and Memory}

\begin{table}[h]
\centering
\begin{tabular}{lcc}
\toprule
Method & Inference Time (ms) & GPU Memory (GB) \\
\midrule
BiomedCLIP & 52 & 8.1 \\
SAM-Med2D & 156 & 12.3 \\
FreqMedCLIP & 81 & 10.7 \\
\bottomrule
\end{tabular}
\caption{Computational costs. FreqMedCLIP is faster than SAM-Med2D while achieving better accuracy. Dual-stream adds modest overhead (29ms vs. BiomedCLIP alone).}
\end{table}

The dual-stream architecture incurs 55\% overhead vs. semantic-only but maintains practical inference speed (~80ms per image on A100). Memory overhead is modest (2.6GB) despite additional parameters.

\subsection{Visualizations}

Figure 2 shows qualitative segmentation results across datasets:
\begin{itemize}
\item FreqMedCLIP produces clean, well-defined segmentation boundaries
\item Frequency stream (shown separately) highlights structural edges; semantic stream captures spatial context
\item Ensemble output combines both: precise boundaries + semantic coherence
\item Comparison to SAM-Med2D shows FreqMedCLIP recovers fine details missed by SAM
\end{itemize}

These results comprehensively validate the FreqMedCLIP architecture across multiple dimensions: segmentation accuracy, boundary precision, computational efficiency, and interpretability through ablation studies.
